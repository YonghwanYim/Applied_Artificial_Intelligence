{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2018_11_05_NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YonghwanYim/Applied_Artificial_Intelligence/blob/master/2018_11_05_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "gNgL-foMsQK4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive # Google Drive 인증\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OYoj1LrWvYNB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "temp = drive.CreateFile({'id' : '1hPFSjrJOnbuWtSZguJy-tNgsq0nlGs64'}) # Generate File\n",
        "temp.GetContentFile('mnist.py') # Rename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XpibvHMSwnaS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "temp = drive.CreateFile({'id' : '1rElYJbh1CcfkjMb4Tdi_ZxvTXw_IQbK0'}) # Generate File\n",
        "temp.GetContentFile('sample_weight.pkl') # Rename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zlkdGAdXxcxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3b4545c-e28d-4385-e81e-488e48a7c44b"
      },
      "cell_type": "code",
      "source": [
        "!ls # 생성된 파일 확인"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  mnist.py  sample_data  sample_weight.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rUKP0aJuyGyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "outputId": "96eef3df-e704-4129-c8e7-b7a6850094b8"
      },
      "cell_type": "code",
      "source": [
        "from mnist import load_mnist\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "def img_show(img):\n",
        "  pil_img = Image.fromarray(np.uint8(img))\n",
        "  display(pil_img)\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize = False, flatten = True)\n",
        "\n",
        "img = x_train[0]\n",
        "label = t_train[0]\n",
        "print(label)\n",
        "\n",
        "print(img.shape)\n",
        "img = img.reshape(28, 28)\n",
        "print(img.shape)\n",
        "\n",
        "img_show(img)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "(784,)\n",
            "(28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy\n/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/H\ntn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+\n/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/f\nv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y3\n5wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F9FD4035F60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bDA_45pByaE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92976e22-eee1-480b-d3b6-57fe0f40d49c"
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "  if x.ndim == 2:\n",
        "    x = x.T\n",
        "    x = x - np.max(x, axis = 0)\n",
        "    y = np.exp(x) / np.sum(np.exp(x), axis = 0)\n",
        "    return y.T\n",
        "  \n",
        "  x = x - np.max(x)\n",
        "  return np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "def get_data():\n",
        "  (x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, flatten = True, one_hot_label = False)\n",
        "  return x_test, t_test\n",
        "\n",
        "def init_network():\n",
        "  with open(\"sample_weight.pkl\", \"rb\") as f:\n",
        "    network = pickle.load(f)\n",
        "  return network\n",
        "\n",
        "def predict(network, x):\n",
        "  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "  \n",
        "  a1 = np.dot(x, W1) + b1\n",
        "  z1 = sigmoid(a1)\n",
        "  a2 = np.dot(z1, W2) + b2\n",
        "  z2 = sigmoid(a2)\n",
        "  a3 = np.dot(z2, W3) + b3\n",
        "  y = softmax(a3)\n",
        "  \n",
        "  return y\n",
        "\n",
        "x, t = get_data()\n",
        "network = init_network()\n",
        "\n",
        "batch_size = 100\n",
        "accuracy_cnt = 0\n",
        "\n",
        "for i in range(0, len(x), batch_size):\n",
        "  x_batch = x[i:i+batch_size]\n",
        "  y_batch = predict(network, x_batch)\n",
        "  p = np.argmax(y_batch, axis = 1)\n",
        "  accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
        "  \n",
        "  #y = predict(network, x[i])\n",
        "  #p = np.argmax(y)\n",
        "  #if p == t[i]:\n",
        "  #  accuracy_cnt += 1\n",
        "\n",
        "print(\"Accuracy: \" + str(float(accuracy_cnt) / len(x)))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7e0bVnNd34uD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7699b050-6fd6-4554-b0e0-2e9604e5f82d"
      },
      "cell_type": "code",
      "source": [
        "x,_ = get_data()\n",
        "network = init_network()\n",
        "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "x.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "RKXmGso64HAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88767ceb-71b8-4131-be17-b97d6c53fbb7"
      },
      "cell_type": "code",
      "source": [
        "x[0].shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "3iB8dBTO5Ka3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff6aeb4f-60f9-467a-f7a7-d494ced92c8e"
      },
      "cell_type": "code",
      "source": [
        "W1.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "KT08CclG5M9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a91828e0-64c7-4154-ac45-88a66a0fc2d5"
      },
      "cell_type": "code",
      "source": [
        "W2.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "lTx2dei95NiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcef117b-f0a4-42f3-d7d5-fdce4cbf1c73"
      },
      "cell_type": "code",
      "source": [
        "W3.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "R0dhBcowIBQ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **2층 신경망 클래스 구현**"
      ]
    },
    {
      "metadata": {
        "id": "eqrxvd2L5Rqg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TwoLayerNet:\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
        "    self.params = {}\n",
        "    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "    self.params['b1'] = np.zeros(hidden_size)\n",
        "    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "    self.params['b2'] = np.zeros(output_size)\n",
        "    #print(self.params['W1'])\n",
        "    #print(self.params['b1'])\n",
        "    #print(self.params['W2'])\n",
        "    #print(self.params['b2'])\n",
        "  \n",
        "  def predict(self, x):\n",
        "    W1, W2 = self.params['W1'], self.params['W2']\n",
        "    b1, b2 = self.params['b1'], self.params['b2']\n",
        "    \n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    y = softmax(a2)\n",
        "    \n",
        "    return y\n",
        "  \n",
        "  def accuracy(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    print(\"y.shape\" + str(y.shape))\n",
        "    y = np.argmax(y, axis = 1)\n",
        "    print(\"y.shape\" + str(y.shape))\n",
        "    accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "    return accuracy\n",
        "  \n",
        "  def loss(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    \n",
        "    return cross_entropy_error(y, t)\n",
        "  \n",
        "  def numerical_gradient(self, x, t):\n",
        "    loss_W = lambda W: self.loss(x, t)\n",
        "    \n",
        "    grads = {}\n",
        "    grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "    grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "    grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "    grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "    \n",
        "    return grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WmVSU04X-3c1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "24024f9f-51ce-42e1-c1f9-8f7e9cd93080"
      },
      "cell_type": "code",
      "source": [
        "x, t = get_data()\n",
        "#network = init_network()\n",
        "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
        "\n",
        "\n",
        "# accuracy_cnt = 0\n",
        "# for i in range(0, len(x)):\n",
        "#   y = network.predict(x[i])\n",
        "#   p = np.argmax(y)\n",
        "#   if p == t[i]:\n",
        "#     accuracy_cnt += 1\n",
        "\n",
        "print(\"x.shape\" + str(x.shape))\n",
        "print(\"t.shape\" + str(t.shape))\n",
        "print(\"Accuracy:\" + str(network.accuracy(x, t)))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape(10000, 784)\n",
            "t.shape(10000,)\n",
            "y.shape(10000, 10)\n",
            "y.shape(10000,)\n",
            "Accuracy:0.0974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IAJu7w1mOBkW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Add Loss **Function**"
      ]
    },
    {
      "metadata": {
        "id": "U14DhYJhOFYY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cross_entropy_error(y, t):\n",
        "  if y.ndim == 1:\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "    \n",
        "  if t.size == y.size:\n",
        "    t = t.argmax(axis = 1)\n",
        "    \n",
        "  batch_size = y.shape[0]\n",
        "  return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z2WmDoSIOp_P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def numerical_gradient(f, x):\n",
        "  h = 0.0001\n",
        "  grad = np.zeros_like(x)\n",
        "  \n",
        "  it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
        "  while not it.finished:\n",
        "    idx = it.multi_index\n",
        "    tmp_val = x[idx]\n",
        "    x[idx] = float(tmp_val) + h\n",
        "    fxh1 = f(x) # f(x+h)\n",
        "    \n",
        "    x[idx] = float(tmp_val) - h\n",
        "    fxh2 = f(x) # f(x-h)\n",
        "    grad[idx] = (fxh1 - fxh2) / (2 * h)\n",
        "    \n",
        "    x[idx] = tmp_val\n",
        "    it.iternext()\n",
        "    \n",
        "  return grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GBua7FCaQa2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "0c85ff18-5dc5-44b5-a498-454ff6d1de82"
      },
      "cell_type": "code",
      "source": [
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, flatten = True, one_hot_label = False)\n",
        "\n",
        "train_loss_list = []\n",
        "\n",
        "# Hyper parameter\n",
        "iters_num = 10000 # 반복횟수\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100 # 미니배치 크기\n",
        "learning_rate = 0.1\n",
        "\n",
        "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "for i in range(iters_num):\n",
        "  \n",
        "  print(\"i: \" + str(i) + \", \" + \"iters_num: \" + str(iters_num))\n",
        "  \n",
        "  # 미니배치 획득\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "  x_batch = x_train[batch_mask]\n",
        "  t_batch = t_train[batch_mask]\n",
        "  \n",
        "  # 기울기 계산 (경사하강법) 소요 시간 (Elapsed time) 측정\n",
        "  t_start = datetime.now()\n",
        "  \n",
        "  # 기울기 계산\n",
        "  print(\"Under calculating each gradient matrix of loss function corresponding to given parameters (W1, b1, W2, b2)...\")\n",
        "  grad = network.numerical_gradient(x_batch, t_batch)\n",
        "  print(\"Calculated!\")\n",
        "  \n",
        "  t_end = datetime.now()\n",
        "  \n",
        "  print(\"Elapsed time per iter: \" + str((t_end - t_start) * (i + 1)))\n",
        "  print(\"Expected left time: \" + str((t_end - t_start) * (iters_num - i - 1)))\n",
        "  \n",
        "  # 매개변수 갱신\n",
        "  for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "    network.params[key] -= learning_rate * grad[key]\n",
        "  print(\"Parameters(W1, b1, W2, b2) are adjusted better!\")\n",
        "  \n",
        "  # 학습 경과 출력\n",
        "  print(\"loss: \" + str(network.loss(x_batch, t_batch)))\n",
        "  print(\"Accuracy_train: \" + str(network.accuracy(x_train, t_train)))\n",
        "  print(\"Accuracy_test: \" + str(network.accuracy(x_test, t_test)))\n",
        "  print()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i: 0, iters_num: 10000\n",
            "Under calculating each gradient matrix of loss function corresponding to given parameters (W1, b1, W2, b2)...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-181bab88059f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;31m# 기울기 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Under calculating each gradient matrix of loss function corresponding to given parameters (W1, b1, W2, b2)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculated!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-d6d064cf8d7e>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-76e7d0d7d10a>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mfxh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# f(x-h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfxh1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfxh2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-d6d064cf8d7e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mloss_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-d6d064cf8d7e>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-d6d064cf8d7e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}